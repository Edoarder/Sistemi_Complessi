{
  
    
        "post0": {
            "title": "[DRAFT - DO NOT SHARE] nbdev + GitHub Codespaces: A New Literate Programming Environment",
            "content": "Today, we are going to show you how to set up a literate programming environment, allowing you to use an IDE (VS Code) and an interactive computing environment (Jupyter), without leaving your browser, for free, in under 5 minutes. You’ll even see how VSCode and Jupyter work together automatically! But first, what is literate programming? And how did I got from a skeptic to a big fan of literate programming in a month? . Introduction . Literate programming is a programming paradigm introduced by Donald Knuth in which a computer program is given an explanation of its logic in a natural language, such as English, interspersed with snippets of macros and traditional source code, from which compilable source code can be generated. According to Knuth, literate programming provides higher-quality programs by forcing programmers to explicitly state the thoughts behind the program. This process makes poorly thought-out design decisions more obvious. Knuth also claims that literate programming provides a first-rate documentation system, which is not an add-on, but is grown naturally in the process of exposition of one’s thoughts during a program’s creation. 1 . When I first learned about literate programming, I was quite skeptical. For the longest time, I had wrongly equated Jupyter notebooks with literate programming. Indeed, Jupyter is a brilliant interactive computing system, which was awarded the Association of Computing Machinery (ACM) Software System Award, and is loved by many developers. However, Jupyter falls short of the literate programming paradigm for the following reasons:2 . It can be difficult to compile source code from notebooks. | It can be difficult to diff and use version control with notebooks because they are not stored in plain text. | It is not clear how to automatically generate documentation from notebooks. | It is not clear how to properly run tests suites when writing code in notebooks. | . My skepticism quickly evaporated when I began using nbdev, a project that extends notebooks to complete the literate programming ideal. I spent a month, full time, using nbdev while contributing to the python library fastcore, and can report that Donald Knuth was definitely onto something. The process of writing prose and tests alongside code forced me to deeply understand why the code does what it does, and to think deeply about its design. Furthermore, the reduced cognitive load and speed of iteration of having documentation, code, and tests in one location boosted my productivity to levels I have never before experienced as a software developer. Furthermore, I found that developing this way bolstered collaboration such that code reviews not only happened faster but were more meaningful. In short, nbdev may be the most profound productivity tool I have ever used. . As a teaser, look how easy it is to instantiate this literate programming environment, which includes a notebook, a docs site and an IDE with all dependencies pre-installed! :point_down: . . Features of nbdev . As discussed in the docs, nbdev provides the following features: . Searchable, hyperlinked documentation, which can be automatically hosted on GitHub Pages for free. | Python modules, following best practices such as automatically defining __all__ with your exported functions, classes, and variables. | Pip and Conda installers. | Tests defined directly in notebooks which run in parallel. This testing system has been thoroughly tested with GitHub Actions. | Navigate and edit your code in a standard text editor or IDE, and export any changes automatically back into your notebooks. | . Since you are in a notebook, you can also add charts, text, links, images, videos, etc, that are included automatically in the documentation of your library, along with standardized documentation generated automatically from your code. This site is an example of docs generated automatically by nbdev. . GitHub Codespaces . Thanks to Conda and nbdev_template, setting up a development environment with nbdev is far easier than it used to be. However, we realized it could be even easier, thanks to a new GitHub product called Codespaces. Codespaces is a fully functional development environment in your browser, accessible directly from GitHub, that provides the following features: . A full VS Code IDE. | An environment that has files from the repository mounted into the environment, along with your GitHub credentials. | A development environment with dependencies pre-installed, backed by Docker. | The ability to serve additional applications on arbitrary ports. For nbdev, we serve a Jupyter notebook server as well as a Jekyll based documentation site. | A shared file system, which facilitates editing code in one browser tab and rendering the results in another. | … and more. | Codespaces enables developers to immediately participate in a project without wasting time on DevOps or complicated setup steps. Most importantly, CodeSpaces with nbdev allows developers to quickly get started with creating their own software with literate programming. . A demo of nbdev + Codespaces . This demo uses the project fastai/fastcore, which was built with nbdev, as an example. First, we can navigate to this repo and launch a Codespace: . . If you are launching a fresh Codespace, it may take several minutes to set up. Once the environment is ready, we can verify that all dependencies we want are installed (in this case fastcore and nbdev): . . Additionally, we can serve an arbitrary number of applications on user-specified ports, which we can open through VSCode as shown below: . . In this case, these applications are a notebook and docs site. Changes to a notebook are reflected immediately in the data docs. Furthermore, we can use the cli command nbdev_build_lib to sync our notebooks with python modules. This functionality is shown below: . . This is amazing! With a click of a button, I was able to: . Launch an IDE with all dependencies pre-installed. | Launch two additional applications: a Jupyter Notebook server on port 8080 and a docs site on port 4000. | Automatically update the docs and modules every time I make a change to a Jupyter notebook. | This is just the tip of the iceberg. There are additional utilities for writing and executing tests, diffing notebooks, special flags for hiding, showing, and collapsing cells in the generated docs, as well as git hooks for automation. This and more functionality is covered in the nbdev docs. . Give It A Try For Yourself . To try out nbdev yourself, take this tutorial, which will walk you through everything you need to know. The tutorial also shows you how to use a repository template with the configuration files necessary to enable Codespaces with nbdev. . You Can Write Blogs With Notebooks, Too! . This blog post was written in fastpages which is also built on nbdev! We recommend fastpages if you want an easy way to blog with Jupyter notebooks. . Additional Resources . The GitHub Codepaces site. | The official docs for Codespaces. | The nbdev docs. | The nbdev GitHub repo. | fastpages: The project used to write this blog. | The GitHub repo fastai/fastcore, which is what we used in this blog post as an example. | . Wikipedia article: Literate Programming &#8617; . | This is not a criticism of Jupyter. Jupyter doesn’t claim to be a full literate programming system. However, people can sometimes (unfairly) judge Jupyter according to this criteria. &#8617; . |",
            "url": "https://edoarder.github.io/Sistemi_Complessi/codespaces",
            "relUrl": "/codespaces",
            "date": " • Nov 2, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Modello di Axelrod",
            "content": "In questa relazione mi occuperò di studiare numericamente e, in parte, analiticiamente un modello Agent-Based di Cultural Dynamics, ovvero un&#39;estensione vettoriale della dinamica delle opinioni: il modello di Axelrod. . Introduzione . Negli ultimi anni si è iniziato a studiare i fenomeni collettivi, emergenti da un insieme di individui, attraverso un formalismo matematico afferente per lo più alla fisica statistica, scienza delle reti e più in generale ai sistemi complessi. Nonostante nella storia della scienza, ed in particolare della fisica, ci siano esempi di studiosi che hanno applicato modelli quantitativi a problemi che riguardavano la sociologia, solo negli ultimi anni si è formata una corrente di studi incentrata appunto sul descrivere il comportamento collettivo umano attraverso modelli matematici: la sociofisica. . Uno dei primi campi di ricerca in questo ambito è stato la dinamica delle opinioni, in cui si cerca di descrivere come una opinione appunto possa essere trasmessa tra vari individui appartenenti ad una rete sociale, cercando di studiarne la dinamica e gli effetti finali &quot;macroscopici&quot;, quali la formazione di un consenso unanime (problema simile a quello della transizione ferromagnetica) o la formazione di cluster di opinioni. Uno dei modelli più importanti di dinamica delle opinioni è il Voter Model. . descrivere voter model . Il modello in esame in questa relazione può essere visto, almeno nella sua versione originale, come un insieme di Voter Model accoppiati. Esiste quindi un numero $F$ di possibili diversi argomenti (features culturali) per i quali un individuo può avere $Q$ diverse opinioni. Esempi di features possono essere “linguaggio, arte, norme tecniche e regole sociali” [1], i quali valori delle opinioni possono cambiare solo attraverso un&#39;influenza sociale, quindi in questo modello non verrano considerati gli effetti di istituzioni centrali e mass media, ma la dinamica avverrà solamente tra individui il che porterà la rete sociale ad autorganizzarsi. . Le proprietà chiave di questo modello sono principalmente due: . Individui che condividono un maggior numero di features hanno maggiore probabilità di interazione (homophily) | Ogni interazione aumenta il numero di features che i due soggetti hanno in comune. | Algoritmo e implementazione . Il modello è definito su un reticolo quadrato di lato $L$, in cui il numero totale degli individui è dunque $N=L^2$. Su ogni sito $i$ è definito un set di $F$ features culturali $q_{i,f}$, numeri interi che vanno da 0 a $Q$ per ogni $f$ che va da 0 a $F$. Nello stato iniziale tutti i valori $q_{i,f}$ sono estratti in maniera casuale da una distribuzione uniforme. . Ad ogni passo temporale viene scelto un sito $i$ random ed un suo primo vicino $j$ sempre random. Viene dunque estratta in maniera casuale una feature $f$ e se risulta che $q_{i,f} neq q_{j,f}$ si prosegue col passo temporale successivo senza apportare modifiche, altrimenti se le due features risultano uguali, si estrae a sorte una seconda features $f&#39;$ tra le features che risultano diverse e la prima si impone uguale alla seconda: $q_{i,f&#39;} = q_{j,f&#39;}$. . L&#39;algoritmo è dunque formato da un ciclo di step elementari del tipo: . Estrazione random di $i$ tra 0 ed $N$ | Estrazione random di $j$ tra i primi vicini di $i$ | Estrazione random di $f$ tra 0 ed $F$ | Se $q_{i,f} neq q_{j,f}$: Step temporale successivo | | Altrimenti se $q_{i,f} = q_{j,f}$: Estrazione random di $f&#39;$ tale che $q_{i,f&#39;} neq q_{j,f&#39;}$ | Si impone $q_{i,f&#39;} = q_{j,f&#39;}$ | Step temporale successivo | | Possiamo notare che nel caso in cui ogni coppia possibile di primi vicini condivida o tutte le features o nessuna, la dinamica del sistema si arresta. Tali stati prendono il nome Absorbing States che per definizione sono gli stati finali dell&#39;evoluzione dinamica del sistema. Possono esistere vari tipi di Absorbing States come vedremo, che possono essere più o meno ordinati. Per sistemi di dimensione finita può essere verificato che la dinamica raggiunge sempre uno stato Absorbing in un tempo finito. . Per costruzione del tipo di interazione, l&#39;evoluzione dinamica tende ad ordinare il sistema e a diminuire il numero dei differenti valori di $q$ relativi a ciascuna features $f$. È intuitivo che per bassi valori di $Q$ il sistema già inizialmente si trovi in uno stato piuttosto omogeneo se confrontato con sistemi con $Q&gt;&gt;1$ per cui la distribuzione dei valori di $q$ è molto più larga, perciò ci si aspetta una maggiore facilità per i casi con bassi valori di $Q$ di raggiungere un consenso, fenomeno verificato come vedremo dalle simulazioni. . Di seguito procederò con l&#39;implementazione dell&#39;algoritmo. Per farlo dovrò prima importare le librerie necessarie, in questo caso solamente NumPy per i calcoli matriciali e Pyplot di Matplotlib per i grafici: . import numpy as np import matplotlib.pyplot as plt import matplotlib as mpl mpl.rcParams[&#39;errorbar.capsize&#39;] = 3 . . Dovrò inoltre definire qualche nuova funzione: . Una funzione che definisce lo stato iniziale di un sistema di $N$ elementi aventi $F$ features, con valori $q_{i,f}$ interi estratti in maniera casuale da una distribuzione uniforme tra 0 e $Q$: | . def iniState(N,F,Q): return np.random.randint(Q,size=(N,F)) . . Una funzione che dato un sito $a$ del reticolo quadrato restituisce un sito $b$ primo vicino di $a$ estratto da una distribuzione uniforme tra 1 e 4: | . def chooseBlat(a): b1=np.random.randint(D*2) if b1==0: if (a+1)%L==0: b=a+1-L else: b=a+1 elif b1==1: if a%L==0: b=a-1+L else: b=a-1 elif b1==2: b=a+L else: b=a-L return b%N . . Una funzione che calcola il numero di collegamenti attivi nel sistema. Per collegamento attivo si intende una coppia di individui primi vicini che condividono lo stesso valore di almeno una features, ma non di tutte le features. Questa funzione ci servirà come parametro di arresto, infatti quando il numero di collegamenti attivi è uguale a zero non è più possibile una variazione dei $q_{i,f}$ di nessun elemento del sistema, quindi la dinamica si arresta e lo stato raggiunto è per definizione un Absorbing State. Inoltre questa funzione ci servirà in seguito per studiare proprio la dinamica del sistema. | . def calcAct(ind): Act=np.zeros((D*N,2),dtype=int)-1 for ai in range(N): bi=Bdx(ai) if (ind[ai]==ind[bi]).any() and (ind[ai]!=ind[bi]).any(): Act[D*ai]=np.array([ai,bi]) ci=Bdw(ai) if(ind[ai]==ind[ci]).any() and (ind[ai]!=ind[ci]).any(): Act[D*ai+1]=np.array([ai,ci]) return (Act[:,0]+1).nonzero()[0].size/(N*D) def Bdx(a): if (a+1)%L==0: b=a+1-L else: b=a+1 return np.int(b) def Bdw(a): b=a+L return np.int(b%N) . . A questo punto è possibile procedere con l&#39;implementazione dell&#39;algoritmo: il codice seguente restituisce in output un vettore ind contenente tutte le varie configurazioni per ogni passo temporale. Ogni componente del vettore ind è composto a sua volta da un vettore ad $N$ componenti che rappresenta la configurazione del sistema ad un certo tempo $t$. Infatti ognuna delle $N$ componenti è formato a sua volta (e per l&#39;ultima volta) da un vettore di dimensione $F$ che contiene i valori $q_{i,f}$ delle features relative all&#39;individuo $i$. . Nell&#39;implementazione è stato più utile considerare come passo temporale, in realtà, un numero di passi dell&#39;algoritmo pari al numero $N$ di elementi che compongono il sistema. In pratica si misura il tempo in unità del numero di elementi. . # Dichiarazioni L=20 # taglia del reticolo D=2 # dimensione spaziale N=L**D # numero totale di elementi del sistema F=10 # numero di features Q=30 # valore massimo che può assumere una feature MODIFICARE QUESTO PER OTTERENERE DINAMICHE DIVERSE TN=100000 # numero massimo di time steps (sovrastimato) TC=TN-1 # inizializzazione del tempo critico per cui la dinamica si arresta ind=np.zeros((TN+1,N,F),dtype=int) # inizializzazione del vettore delle configurazioni ind[0]=iniState(N,F,Q) # configurazione iniziale indt=np.zeros((N,F),dtype=int) # configurazione temporanea nA=np.zeros(TN) # vettore del numero di collegamenti attivi, nel tempo for tnn in np.arange(TN): indt=ind[tnn].copy() for tn in np.arange(N): a=np.random.randint(N) b=chooseBlat(a) if (indt[a]!=indt[b]).any() and (indt[a]==indt[b]).any(): c=np.random.randint(F) if indt[a,c]==indt[b,c]: dd=np.random.randint(F) for Fi in range(F): d=(dd+Fi)%F if indt[a,d]!=indt[b,d]: indt[a,d]=indt[b,d].copy() break nA[tnn]=calcAct(ind[tnn]) if nA[tnn]==0: TC=tnn break ind[tnn+1]=indt.copy() . . Per rappresentare graficamente l&#39;evoluzione nel tempo delle configurazioni del sistema, quindi in pratica l&#39;evoluzione delle componenti di ind, è stato necessario manipolare un po&#39; il vettore per renderlo quadrato ed animarlo attraverso delle funzioni di matplotlib. . %matplotlib widget from matplotlib.animation import FuncAnimation import matplotlib.animation as animation aa=np.zeros((TN,L,L),dtype=int) aa=np.reshape(ind[:,:,0],(TN+1,L,L)) animation_type = &#39;pcolor&#39; fig, ax = plt.subplots(figsize=(4, 4)) ax.set(xlim=(0, L-1), ylim=(0, L-1)) #aggiungere titolo x=np.arange(L) y=np.arange(L) t=np.arange(TC) X,Y,T=np.meshgrid(x, y, t) if animation_type == &#39;pcolor&#39;: cax = ax.pcolormesh(x, y, aa[0,:-1, :-1], cmap=&#39;jet&#39;) #fig.colorbar(cax) def animate(i): cax.set_array(aa[i,:-1, :-1].flatten()) anim = FuncAnimation(fig, animate, frames=len(t)-1, repeat=False, interval=10) fig.show() print(&quot;Tempo critico = &quot;+str(TC)) . . Per motivi di programmazione della pagina web non è stato possibile inserire le animazioni di matplotlib. Il codice sopra è funzionante e se fatto girare restituirà una delle animazioni sotto, che sono state invece pubblicate su YouTube per poter essere visualizzate in questa pagina. . . Studio degli stati finali: Absorbing States . La prima parte di questa relazione andrà a presentare i dati relativi agli studi effettuati appunto sulle proprietà degli Absorbing States finali. L&#39;osservabile che considereremo come parametro d&#39;ordine in questa parte è una sorta di densità di magnetizzazione, $⟨s_{max}⟩$, ovvero il numero di siti che presentano lo stesso valore $q$ di una certa feature $f$ per cui questa grandezza risulti massima, normalizzato col numero totale di elementi e mediato su varie realizzazioni della dinamica effettuate con gli stessi parametri ma stati iniziali e realizzazioni diverse del processo. Il parametro attraverso il quale verrà studiato l&#39;andamento di $⟨s_{max}⟩$ è $Q$, ovvero il numero di possibili scelte per ogni feature. . Per calcolare $⟨s_{max}⟩$ è necessario introdurre una nuova funzione calcMag che prende in input una configurazione, nel caso seguente la configurazione finale, e calcola per ogni feature $F$ quanti individui condividono lo stesso valore $q$. In output la funzione restituisce il valore massimo di questa matrice $F times Q$, ovvero il numero massimo di individui che hanno lo stesso $q$, a prescindere dalla feature a cui si riferisce, normalizzato al numero di elementi del sistema: . def calcMag(indi): mag=np.zeros((F,Q)) for f in range(F): for q in range(Q): for i in range(N): if indi[i,f]==q: mag[f,q]+=1 return np.amax(mag)/N . . Di seguito l&#39;implementazione del codice che restituisce in output i valori di $⟨s_{max}⟩$ in funzione di $Q$ per tre diverse taglie del sistema: . Lv=np.array([10,20,30]) D=2 F=10 TN=100000 rep=30 Qrange=np.array([2,5,10,20,25,30,35,40,60,100]) qrange=np.arange(Qrange.size) magv=np.zeros((Lv.size,Qrange.size,rep)) TCv=np.zeros((Lv.size,Qrange.size,rep)) nA=np.zeros((Lv.size,Qrange.size,TN,rep)) ll=0 for L in Lv: N=L**D for rip in range(rep): q=0 for Q in Qrange: TC=TN-1 ind=iniState(N,F,Q) indt=np.zeros((N,F),dtype=int) mag=0 for tnn in np.arange(TN): indt=ind.copy() for tn in np.arange(N): a=np.random.randint(N) b=chooseBlat(a) if (indt[a]!=indt[b]).any() and (indt[a]==indt[b]).any(): c=np.random.randint(F) if indt[a,c]==indt[b,c]: dd=np.random.randint(F) for Fi in range(F): d=(dd+Fi)%F if indt[a,d]!=indt[b,d]: indt[a,d]=indt[b,d].copy() break ind=indt.copy() nA[ll,q,tnn,rip]=calcAct(ind) if nA[ll,q,tnn,rip]==0: TC=tnn break if TC==TN-1: print(&quot;Error: System Not Frozen, try to increase TN or reduce L&quot;) #print(&#39;{} r&#39;.format(tnn), end=&quot;&quot;) magv[ll,q,rip]=calcMag(ind) TCv[ll,q,rip]=TC q+=1 #print(&#39;{} r&#39;.format(rip), end=&quot;&quot;) ll+=1 #print() . . I risultati sono riportati nel grafico seguente e si riferiscono a valori di $L=10,20,30$ ed $F=10$. . for i in range(Lv.size): plt.errorbar(Qrange,magv[i].mean(axis=1),yerr=magv[i].std(axis=1), label=&quot;L=&quot;+str(Lv[i]), marker=&#39;.&#39;) plt.xlabel(&#39;Q&#39;) plt.ylabel(&#39;$⟨s_{max}⟩$&#39;) plt.legend() plt.show() . . Dal grafico precedente possiamo notare la presenza di una transizione di fase, infatti a bassi valori di $Q$ corrispondono valori di $⟨s_{max}⟩$ pressoché unitari mentre per grandi valori $Q$ $⟨s_{max}⟩$ tende a zero. Queste due fasi sono separate da una graduale diminuzione che diventa sempre più accentata aumentando la taglia del sistema, lasciando immaginare che nel limite termodinamico $N to0$ il sistema presenti una discontinuità nel valore di $⟨s_{max}⟩$ e quindi una transizione di fase di seconda specie come quello della transizione ferromagnetica. Si può stimare il punto critico in corrispondenza di un valore di $Q$ compreso tra 30 e 40. . Studio dei tempi critici . Un altro parametro interessante, sempre relativo agli stati finali, è il tempo che ci impiega in media un sistema a raggiungere uno stato Absorbing, detto tempo critico $t_c$, anche in questo caso infatti si possono notare gli effetti di una transizione di fase: . Lv=np.array([10,15,20,25,30]) D=2 F=10 TN=100000 rep=30 Qrange=np.array([5,10,20,30,40,60,80,100]) #magv=np.zeros((Lv.size,Qrange.size,rep)) TCv=np.zeros((Lv.size,Qrange.size,rep)) nA=np.zeros((Lv.size,Qrange.size,TN,rep)) ll=0 for L in Lv: N=L**D for rip in range(rep): q=0 for Q in Qrange: TC=TN-1 ind=iniState(N,F,Q) indt=np.zeros((N,F),dtype=int) mag=0 for tnn in np.arange(TN): indt=ind.copy() for tn in np.arange(N): # Elementary Step a=np.random.randint(N) b=chooseBlat(a) if (indt[a]!=indt[b]).any() and (indt[a]==indt[b]).any(): c=np.random.randint(F) if indt[a,c]==indt[b,c]: dd=np.random.randint(F) for Fi in range(F): d=(dd+Fi)%F if indt[a,d]!=indt[b,d]: indt[a,d]=indt[b,d].copy() break ind=indt.copy() nA[ll,q,tnn,rip]=calcAct(ind) if nA[ll,q,tnn,rip]==0: TC=tnn break #print(&#39;{} r&#39;.format(tnn), end=&quot;&quot;) #magv[ll,q,rip]=calcMag(ind) TCv[ll,q,rip]=TC q+=1 #print(&#39;{} r&#39;.format(L), end=&quot;&quot;) ll+=1 #print() . . # con i parametri del codice di sotto for ll in range(Lv.size): # ancora da far girare, ne servono di meno cmq TCM=int(np.amax(TCv[ll])) plt.errorbar(Qrange,TCv[ll].mean(axis=1),yerr=TCv[ll].std(axis=1), label=&quot;L=&quot;+str(Lv[ll]),marker=&quot;.&quot;) #plt.plot(Qrange,nA[0,Q].mean(axis=1)[:TCM]) plt.xlabel(&#39;Q&#39;) plt.ylabel(&#39;$t_c$&#39;) #plt.yscale(&quot;log&quot;) plt.legend() #plt.plot(range(TC),nA[:TC]/N) #plt.xscale(&quot;log&quot;) plt.show() . . # con i parametri del codice di sotto for ll in range(0,Lv.size,2): # ancora da far girare, ne servono di meno cmq TCM=int(np.amax(TCv[ll])) plt.errorbar(Qrange,TCv[ll].mean(axis=1),yerr=TCv[ll].std(axis=1), label=&quot;L=&quot;+str(Lv[ll]),marker=&quot;.&quot;) #plt.plot(Qrange,nA[0,Q].mean(axis=1)[:TCM]) plt.xlabel(&#39;Q&#39;) plt.ylabel(&#39;$t_c$&#39;) #plt.xscale(&quot;log&quot;) plt.legend() #plt.plot(range(TC),nA[:TC]/N) #plt.xscale(&quot;log&quot;) plt.show() . . Dal grafico precedente possiamo notare che il tempo critico corrispondente a valori di $Q$ subcritici tende ad aumentare al crescere della taglia del sistema, presentando un picco proprio intorno a $Q_c$, al di sopra inceve $t_c$ tende ad un valore finito a prescindere dalla taglia del sistema. . Per studiare questo comportamento andiamo a graficare i tempi critici questa volta in funzione di $L$: . for Q in range(Qrange.size): plt.errorbar(Lv,TCv[:,Q].mean(axis=1),yerr=TCv[:,Q].std(axis=1), marker=&#39;.&#39;, label=&quot;Q=&quot;+str(Qrange[Q])) plt.xlabel(&#39;L&#39;) plt.ylabel(&#39;$t_c$&#39;) #plt.xscale(&quot;log&quot;) #plt.yscale(&quot;log&quot;) plt.legend() plt.show() . . Come possiamo notare dal grafico precedente per valori $Q$ supercrici $t_c$ sembra diminuire la sua crescita fino a rimanere pressoché costante al variare di $L$. . for Q in range(Qrange.size): plt.errorbar(Lv,TCv[:,Q].mean(axis=1),yerr=TCv[:,Q].std(axis=1), marker=&#39;.&#39;, label=&quot;Q=&quot;+str(Qrange[Q])) plt.xlabel(&#39;L&#39;) plt.ylabel(&#39;Tc&#39;) plt.xscale(&quot;log&quot;) plt.yscale(&quot;log&quot;) plt.legend() plt.show() . . for Q in range(Qrange.size): plt.errorbar(Lv,TCv[:,Q].mean(axis=1),yerr=TCv[:,Q].std(axis=1), marker=&#39;.&#39;, label=&quot;Q=&quot;+str(Qrange[Q])) plt.plot(Lv,np.polyfit(Lv,TCv[:,Q].mean(axis=1),2)[0]*Lv**2+np.polyfit(Lv,TCv[:,Q].mean(axis=1),2)[1]*Lv+np.polyfit(Lv,TCv[:,Q].mean(axis=1),2)[2]) plt.xlabel(&#39;L&#39;) plt.ylabel(&#39;Tc&#39;) plt.xscale(&quot;log&quot;) plt.yscale(&quot;log&quot;) print(&quot;Q = &quot; + str(Qrange[Q]) +&quot;: Fit Slop = &quot; + str(np.polyfit(np.log(Lv),np.log(TCv[:,Q].mean(axis=1)),1)[0])) #plt.legend() plt.show() . . Q = 5: Fit Slop = 2.0982423722444743 Q = 10: Fit Slop = 2.0616719408001645 Q = 20: Fit Slop = 1.9471721662831847 Q = 30: Fit Slop = 1.8299025446394042 Q = 40: Fit Slop = 2.069247222465267 Q = 60: Fit Slop = 1.4671073272337474 Q = 80: Fit Slop = 0.7674905225381033 . for Q in range(Qrange.size): plt.plot(Qrange,np.polyfit(np.log(Lv),np.log(TCv[:].mean(axis=2)),1)[0],marker=&quot;.&quot;,color=&quot;Purple&quot;) . . for Q in np.array([0,1,3,4,5]): plt.errorbar(Lv,TCv[:,Q].mean(axis=1),yerr=TCv[:,Q].std(axis=1), marker=&#39;.&#39;, label=&quot;Q=&quot;+str(Qrange[Q])) plt.xlabel(&#39;L&#39;) plt.ylabel(&#39;Tc&#39;) plt.xscale(&quot;log&quot;) plt.yscale(&quot;log&quot;) plt.legend() plt.show() . . for Q in np.array([1,2,3,4]): plt.errorbar(Lv,TCv[:,Q].mean(axis=1),yerr=TCv[:,Q].std(axis=1), marker=&#39;.&#39;, label=&quot;Q=&quot;+str(Qrange[Q])) plt.xlabel(&#39;L&#39;) plt.ylabel(&#39;Tc&#39;) plt.xscale(&quot;log&quot;) plt.yscale(&quot;log&quot;) plt.legend() plt.show() . . for Q in np.array([2,3,4]): plt.errorbar(Lv,TCv[:,Q].mean(axis=1),yerr=TCv[:,Q].std(axis=1), marker=&#39;.&#39;, label=&quot;Q=&quot;+str(Qrange[Q])) plt.plot(Lv,np.polyfit(Lv,TCv[:,Q].mean(axis=1),2)[0]*Lv**2+np.polyfit(Lv,TCv[:,Q].mean(axis=1),2)[1]*Lv+np.polyfit(Lv,TCv[:,Q].mean(axis=1),2)[2]) plt.xlabel(&#39;L&#39;) plt.ylabel(&#39;Tc&#39;) plt.xscale(&quot;log&quot;) plt.yscale(&quot;log&quot;) print(&quot;Q = &quot; + str(Qrange[Q]) +&quot;: Fit Slop = &quot; + str(np.polyfit(np.log(Lv),np.log(TCv[:,Q].mean(axis=1)),1)[0])) plt.legend() plt.show() . . Q = 20: Fit Slop = 1.9471721662831847 Q = 30: Fit Slop = 1.8299025446394042 Q = 40: Fit Slop = 2.069247222465267 . for Q in np.array([2]): plt.errorbar(Lv,TCv[:,Q].mean(axis=1),yerr=TCv[:,Q].std(axis=1), marker=&#39;.&#39;, label=&quot;Q=&quot;+str(Qrange[Q])) plt.plot(Lv,np.polyfit(Lv,TCv[:,Q].mean(axis=1),2)[0]*Lv**2+np.polyfit(Lv,TCv[:,Q].mean(axis=1),2)[1]*Lv+np.polyfit(Lv,TCv[:,Q].mean(axis=1),2)[2]) plt.xlabel(&#39;L&#39;) plt.ylabel(&#39;Tc&#39;) plt.xscale(&quot;log&quot;) plt.yscale(&quot;log&quot;) print(&quot;Q = &quot; + str(Qrange[Q]) +&quot;: Fit Slop = &quot; + str(np.polyfit(np.log(Lv),np.log(TCv[:,Q].mean(axis=1)),1)[0])) plt.legend() plt.show() . . Q = 20: Fit Slop = 1.9471721662831847 . Studio della dinamica . Fino a questo punto ci siamo occupati dello studio degli stati finali, al termine dell&#39;evoluzione dinamica. Ora passiamo invece allo studio della dinamica stessa. In questo caso il parametro d&#39;ordine che considereremo è la densità di collegamenti attivi $n_A$, definiti come prima, calcolata attraverso la funzione calcAct. Questa grandezza caratterizza lo stato della dinamica e risulta nulla in una configurazione Absorbing. In realtà questa proprietà è stata usata finora come criterio di arresto dell&#39;algoritmo, che veniva bloccato una volta che $n_A$ risultava uguale a zero. . Il comportamento di $n_A$ al variare del tempo è una delle caratteristiche che rende questo modello ben distinto dal Voter Model, sua controparte scalare, ed interessante perchè emergente proprio dalla generalizzazione al caso vettoriale, producendo una fenomenologia nuova e non banale. . Il codice sottostante restituisce il grafico dell&#39;andamanento di $n_A$ nel tempo per alcuni diversi valori di $Q$, per $L=10$ ed $F=8$: . #%%time Lv=np.array([10]) D=2 F=8 TN=100000 rep=30 Qrange=np.array([2,5,10,20,30,40,60,100]) qrange=np.arange(Qrange.size) magv=np.zeros((Lv.size,Qrange.size,rep)) TCv=np.zeros((Lv.size,Qrange.size,rep)) nA=np.zeros((Lv.size,Qrange.size,TN,rep)) ll=0 for L in Lv: N=L**D for rip in range(rep): q=0 for Q in Qrange: TC=TN-1 ind=iniState(N,F,Q) indt=np.zeros((N,F),dtype=int) mag=0 for tnn in np.arange(TN): indt=ind.copy() for tn in np.arange(N): a=np.random.randint(N) b=chooseBlat(a) if (indt[a]!=indt[b]).any() and (indt[a]==indt[b]).any(): c=np.random.randint(F) if indt[a,c]==indt[b,c]: dd=np.random.randint(F) for Fi in range(F): d=(dd+Fi)%F if indt[a,d]!=indt[b,d]: indt[a,d]=indt[b,d].copy() break ind=indt.copy() nA[ll,q,tnn,rip]=calcAct(ind) mag=calcMag(ind) # magnetization if nA[ll,q,tnn,rip]==0: TC=tnn break #print(&#39;{} r&#39;.format(tnn), end=&quot;&quot;) magv[ll,q,rip]=np.amax(mag) TCv[ll,q,rip]=TC q+=1 print(&#39;{} r&#39;.format(rip), end=&quot;&quot;) ll+=1 print() # fig only for L=20 TCM=int(np.amax(TCv[0])) for Q in range(Qrange.size): #plt.errorbar(range(TCM),nA[Q].mean(axis=1)[:TCM],yerr=nA[Q].std(axis=1)[:TCM], label=&quot;Q=&quot;+str(Qrange[Q])) plt.plot(range(TCM),nA[0,Q].mean(axis=1)[:TCM]) plt.xlabel(&#39;t&#39;) plt.ylabel(&#39;Activity&#39;) plt.xscale(&quot;log&quot;) #plt.legend() #plt.plot(range(TC),nA[:TC]/N) #plt.xscale(&quot;log&quot;) plt.show() . . 29 . Come possiamo notare dal grafico precedente, per bassi valori di $Q$ il sistema presenta una lenta diminuzione di $n_A$, con la maggior parte dei collegamenti tra individui attivi, per poi diminuire più rapidamente per tempi lungi e raggiungere uno stato Absorbing, come abbiamo visto, in un tempo proporzionale al numero di elementi che costituiscono il sistema. Per grandi valori di $Q$ dopo un breve periodo transiente iniziale $n_A$ diminuisce velocemente e raggiunge uno stato Absorbing in un tempo finito. . Il comportamento interessante avviene per valori intermedi di $Q$ in cui si ha una diminuzione iniziale dei collegamenti attivi, un aumento verso un picco di attività e poi una diminuzione finale che finisce col raggiungimento di un Absorbing State. . La dinamica è essenzialmente un processo di formazione ed ingrandimento di cluster di individui che condividono gli stessi valori di features. Per $Q&lt;Q_c$ il processo va avanti per tempi dell&#39;ordine di $N=L^2$ e tende a creare cluster di dimensione comparabile a quella del sistema, mentre per $Q&gt;Q_c$ il processo crea cluster di dimensione finita in un tempo finito. . Questo comportamento non monotono evidenziato nei grafici precedenti è caratteristico del modello di Axelrod e nella prossima sezione andremo a studiarlo attraverso un approccio analitico. . %%time Lv=np.array([10,15,20]) D=2 F=8 TN=100000 rep=25 Qrange=np.array([2,5,10,20,30,40,60,100]) qrange=np.arange(Qrange.size) magv=np.zeros((Lv.size,Qrange.size,rep)) TCv=np.zeros((Lv.size,Qrange.size,rep)) nA=np.zeros((Lv.size,Qrange.size,TN,rep)) ll=0 for L in Lv: N=L**D for rip in range(rep): q=0 for Q in Qrange: TC=TN-1 ind=np.zeros((N,F),dtype=int) ind=iniState(N,F,Q) indt=np.zeros((N,F),dtype=int) mag=0 for tnn in np.arange(TN): Act=np.zeros((D*N,2),dtype=int)-1 for ai in range(N): bi=Bdx(ai) if (ind[ai]==ind[bi]).any() and (ind[ai]!=ind[bi]).any(): Act[D*ai]=np.array([ai,bi]) ci=Bdw(ai) if(ind[ai]==ind[ci]).any() and (ind[ai]!=ind[ci]).any(): Act[D*ai+1]=np.array([ai,ci]) nA[ll,q,tnn,rip]=(Act[:,0]+1).nonzero()[0].size/N/2 if nA[ll,q,tnn,rip]==0: TC=tnn break mag=calcMag(ind) # magnetization indt=ind.copy() for tn in np.arange(N): a=np.random.randint(N) b=chooseBlat(a) if (indt[a]!=indt[b]).any() and (indt[a]==indt[b]).any(): c=np.random.randint(F) if indt[a,c]==indt[b,c]: dd=np.random.randint(F) for Fi in range(F): d=(dd+Fi)%F if indt[a,d]!=indt[b,d]: indt[a,d]=indt[b,d].copy() break ind=indt.copy() #print(&#39;{} r&#39;.format(tnn), end=&quot;&quot;) magv[ll,q,rip]=np.amax(mag) TCv[ll,q,rip]=TC q+=1 print(&#39;{} r&#39;.format(rip), end=&quot;&quot;) ll+=1 print() # fig only for L=20 TCM=int(np.amax(TCv[2])) for Q in range(Qrange.size): #plt.errorbar(range(TCM),nA[Q].mean(axis=1)[:TCM],yerr=nA[Q].std(axis=1)[:TCM], label=&quot;Q=&quot;+str(Qrange[Q])) plt.plot(range(TCM),nA[2,Q].mean(axis=1)[:TCM]) plt.xlabel(&#39;t&#39;) plt.ylabel(&#39;Activity&#39;) plt.xscale(&quot;log&quot;) #plt.legend() #plt.plot(range(TC),nA[:TC]/N) #plt.xscale(&quot;log&quot;) plt.show() . . 24 . CPU times: user 6h 48min 55s, sys: 14.1 s, total: 6h 49min 9s Wall time: 6h 49min 6s . Master Equation . Il comportamento dinamico del modello può essere studiato attraverso l&#39;analisi di un singolo collegamento in approssimazione di campo medio. . Dato un collegamento tra due elementi primi vicini scelti casualmente, il collegamento si dice di tipo $m$ se i due individui hanno in comune $m$ features e $F-m$ features differenti. Si definisce $P_m(t)$ la probabilità che un collegamento scelto a caso sia di tipo $m$ al tempo $t$. Al tempo $t=0$ poichè i valori delle features sono estratte a caso, la probabilità che il collegamento sia di tipo $m$ è data dalla distribuzione binomiale $P_m(0)= binom{F}{m} rho_0^m(1- rho_0)^{F-m}$ con $ rho_0=$Prob$[q_{i,f}=q_{j,f}]$, che, poichè al tempo $t=0$ i valori delle features sono estratti da una distribuzione uniforme segue che $ rho_0=1/Q$. . In approssimazione di campo medio la master equation risulta essere: . $$ frac{d P_m}{dt}= sum_{k=1}^{F-1} frac{k}{F} P_k [ delta_{m,k+1}- delta_{m,k}+(g-1) sum_{n=0}^F (P_n W_{n,m}^{(k)}-P_m W_{m,n}^{(k)}) ] $$ . dove è sottintesa la dipendenza delle probabilità dal tempo $t$. $g$ è il numero di coordinazione del reticolo, nel nostro caso 2D, $g=4$ e $W_{n,m}^{(k)}$ è la probabilità di transizione di un collegamento dal tipo $n$ ad uno $m$, dovuto al cambiamento di un collegamento vicino di tipo $k$. . Questa equazione descrive come il numero di collegamenti di tipo $m$ vari in funzione dalla dinamica: $ frac{k}{F} P_k$ è la probabilità di scegliere un collegamento di tipo $k$ e di selezionare una delle $k$ features che i due individui condividono. Se $k=m-1$ viene creato un nuovo collegamento di tipo $m$, se invece $k=m$ un collegamento di tipo $m$ viene distrutto. Questo spiega i primi due termini della parentesi quadra nell&#39;equazione precedente. I termini restanti prendono invece in considerazione il cambiamento dei tipi degli altri $(g-1)$ collegamenti del sito in esame con gli altri primi vicini. . Per calcolare le probabilità di transizione $W_{n,m}^{(k)}$ è necessario analizzare in dettaglio ogni processo possibile. Per mostrare come sono stati calcolati i valori di $W$ consideriamo ad esempio un collegamento di tipo $k=1$ adiacente ad uno di tipo $n=0$. Senza perdere di generalità ipotizziamo che gli individui $i$ e $j$ agli estremi del collegamento $k=1$ abbiano rispettivamente i valori delle features: $(0,0,...,0)$ e $(0,q_2,...,q_F)$ con $q_j neq0$ $ forall j$. Il terzo sito $l$, primo vicino di $j$, non condividendo con $j$ nessuna feature (collegamento di tipo $n=0$) possiede i seguenti valori delle features: $(q_1&#39;,q_2&#39;,...,q_F&#39;)$ con $q_1&#39; neq0$ e $q_j&#39; neq q_j$ $ forall j&gt;1$. Quando $k$ da tipo $1$ diventa tipo $2$, immaginiamo per esempio che $q_2 to 0$, l&#39;altro collegamento $n$ adiacente può diventare un collegamento di tipo $1$ se $q_2&#39;=0$ oppure rimanere $0$ se $q_2&#39; neq0$. Nello spirito dell&#39;approssimazione di campo medio introduciamo la probabilità $ rho =$Prob$(q_2&#39;=0)$ che considereremo dipendente dal tempo. Quindi nel nostro esempio risulterebbero $W_{0,1}^{(1)}= rho$ e $W_{0,0}^{(1)}=1- rho$. . Attraverso questo metodo sono andato a calcolare le altre probabilità di transizione per il caso $F=3$. Poichè nel caso in cui $i$ e $j$ non abbiano features in comune o ce le abbiano tutte uguali non avviene una dinamica, il collegamento $n$ non ha probabilità di transizione quindi $ W^{(0)}_{n,m}=W^{(0)}_{m,n}=0 quad forall m,n$ e nella stessa maniera $W^{(3)}_{n,m}=W^{(3)}_{m,n}=0$. Inoltre calcolando i valori di per tutti i casi possibili ho notato che $W^{(1)}_{n,m}=W^{(2)}_{n,m} quad forall m,n$ quindi eviterò di riportare gli apici nel seguito, ritenendo il valore di $W$ uguale sia nel caso $k=1$ che nel caso $k=2$: . $$W_{0,0}=1- rho quad quad W_{0,1}= rho$$ $$W_{1,0}= frac{1}{3} quad quad W_{1,1}= frac{2}{3}(1- rho) quad quad W_{1,2}= frac{2}{3} rho$$ $$W_{2,1}= frac{2}{3} quad quad W_{2,2}= frac{1}{3}(1- rho) quad quad W_{2,3}= frac{1}{3} rho$$ $$W_{3,2}=0 quad quad W_{3,3}=1$$ . Per tutti gli altri valori di $n$ ed $m$ $W_{n,m}=0$. . Per risolvere la master equation, che in pratica è un sistema di $F+1$ equazioni differenziali ordinarie del primo ordine non lineari accoppiate, non resta che specificare la dinamica di $ rho(t)$. Sempre nello spirito dell&#39;approssimazione di campo medio possiamo scrivere $ rho= sum_k k P_k/F$, ricordandosi la condizione iniziale $ rho(0)=1/Q$. Ciò equivale a dire che tra due individui qualsiasi c&#39;è un collegamento, e quindi che la probabilità che una feature abbia lo stesso valore per entrambi gli individui può essere espressa in termini di $P_m$. . L&#39;integrazione numerica, effettuata attraverso il metodo di Crank–Nicolson, mostra l&#39;andamento della densità di collegamenti attivi calcolata come $n_A(t)= sum_{k=1}^{F-1}P_k(t)$, da cui risulta un comportamento non monotono del tutto simile a quello evidenziato dalle simulazioni: . F=3 T=1000 P=np.zeros((T+1,F+1)) def W(r): W=np.zeros((F+1,F+1)) # n,m W[0]=np.array([1-r,r,0,0]) W[1]=np.array([1/3,(2/3)*(1-r),(2/3)*r,0]) W[2]=np.array([0,2/3,(1/3)*(1-r),(1/3)*r]) W[3]=np.array([0,0,1,0]) return W def fact(n): f=1 for i in range(1,n+1): f*=i return f def CB(n,k): return fact(n)/(fact(k)*fact(n-k)) def Prob0(r0): P0=np.zeros(F+1) for m in range(F+1): P0[m]=CB(F,m)*r0**m*(1-r0)**(F-m) return P0 def delta(i,j): if i==j: return 1 else: return 0 Qrange=np.array([10,20,50,70,79,100]) for Q in Qrange: r0=1/Q P[0]=Prob0(r0) # initial values, normalized by construction for t in range(1): r=0 for k1 in range(F+1): r+=k1*P[t,k1]/F for m in range(F+1): A=np.zeros((2,F+1)) for k in range(1,F): B=0 for n in range(F+1): B+=(P[t,n]*W(r)[n,m]-P[t,m]*W(r)[m,n]) A[0]+=P[t,k]*(k/F)*(delta(m,k+1)-delta(m,k)+3*B) P[t+1,m]=P[t,m]+A[0,m] P[t+1]=P[t+1]/P[t+1].sum() # normalization for t in range(1,T): r=0 for k1 in range(F+1): r+=k1*P[t,k1]/F for m in range(F+1): A[1]=np.zeros(F+1) for k in range(1,F): B=0 for n in range(F+1): B+=(P[t,n]*W(r)[n,m]-P[t,m]*W(r)[m,n]) A[1,m]+=P[t,k]*(k/F)*(delta(m,k+1)-delta(m,k)+3*B) P[t+1,m]=P[t,m]+(A[0,m]+A[1,m])/2 P[t+1]=P[t+1]/P[t+1].sum() # normalization A[0]=A[1].copy() nA=np.zeros(T+1) for i in range(1,F): nA+=P[:,i] #for i in range(F+1): # plt.plot(range(T+1),P[:,i],label=&quot;P(&quot;+str(i)+&quot;)&quot;) plt.plot(range(T+1),nA,label=&quot;Q=&quot;+str(Q)) plt.xscale(&quot;log&quot;) plt.ylim(0) plt.legend() plt.show() . . Come possiamo notare dal grafico sopra per valori di $Q&gt;Q_c$ si osserva una graduale diminuzione di $n_A$ che poi finisce a zero, mentre per $Q&lt;Q_c$ si osserva lo stesso una diminuzione iniziale seguita però da una crescita sempre più ripida per valori di $Q$ che si avvicinano a qullo critico. A differenza dei grafici restituiti dalle simulzioni, per $Q&lt;Q_c$ non si osserva un picco e poi una diminuzione verso zero, ma $n_A$ satura e rimane costante ad un valore finito. Questo fenomeno può essere spiegato ricordandosi che le simulzioni sono state effettuate considerando (per necessità) il numero di individui finito, al contrario nella master equation non ci sono termini che fanno riferimento alla taglia del sistema che viene considerata dunque implicitamente infinita. Possiamo immaginare quindi il sistema in un continuo e costante ingrandimento dei cluster che prosegue indefinitamente. . Andando a graficare le probabilità negli gli stati finali della dinamica per diversi valori di $Q$, possiamo anche qua notare una evidente transizione di fase, per esempio per quanto riguarda $n_A$ si può notare una discontinuità per $Q=Q_c$ e lo stesso per $P(0)$ e $P(F)$. . F=3 T=1000 Qmax=10000 P=np.zeros((T+1,F+1)) Pp=np.zeros((Qmax-2,F+1)) nA=np.zeros(Qmax-2) Qrange=np.arange(2,Qmax) for Q in Qrange: r0=1/Q P[0]=Prob0(r0) # initial values, normalized by construction for t in range(1): r=0 for k1 in range(F+1): r+=k1*P[t,k1]/F for m in range(F+1): A=np.zeros((2,F+1)) for k in range(1,F): B=0 for n in range(F+1): B+=(P[t,n]*W(r)[n,m]-P[t,m]*W(r)[m,n]) A[0]+=P[t,k]*(k/F)*(delta(m,k+1)-delta(m,k)+3*B) P[t+1,m]=P[t,m]+A[0,m] P[t+1]=P[t+1]/P[t+1].sum() # normalization for t in range(1,T): r=0 for k1 in range(F+1): r+=k1*P[t,k1]/F for m in range(F+1): A[1]=np.zeros(F+1) for k in range(1,F): B=0 for n in range(F+1): B+=(P[t,n]*W(r)[n,m]-P[t,m]*W(r)[m,n]) A[1,m]+=P[t,k]*(k/F)*(delta(m,k+1)-delta(m,k)+3*B) P[t+1,m]=P[t,m]+(A[0,m]+A[1,m])/2 P[t+1]=P[t+1]/P[t+1].sum() # normalization A[0]=A[1].copy() Pp[Q-2]=P[T] nA[Q-2]=Pp[Q-2,1]+Pp[Q-2,2] plt.plot(Qrange,nA,label=&quot;nA&quot;) plt.plot(Qrange,Pp[:,0],label=&quot;P(0)&quot;) plt.plot(Qrange,Pp[:,F],label=&quot;P(F+1)&quot;) plt.xscale(&quot;log&quot;) plt.ylim(0) plt.legend() plt.show() . . plt.plot(Qrange,Pp[:,0],label=&quot;P(0)&quot;) plt.plot(Qrange,Pp[:,F],label=&quot;P(F)&quot;) plt.plot(Qrange,nA,label=&quot;nA&quot;) plt.xlabel(&quot;Q&quot;) plt.xscale(&quot;log&quot;) plt.ylim(0) plt.legend() plt.show() . . Conclusioni . Bibliografia . Axelrod, R., 1997, J. Conﬂict Resolut. 41(2), 203. . C. Castellano, M. Marsili, and A. Vespignani, 2000, Phys. Rev. Lett. 85(16), 3536. . C. Castellano, S. Fortunato and V. Loreto, “Statistical Physics of Social Dynamics, Rev. Mod. Phys. 81, 591 (2009). .",
            "url": "https://edoarder.github.io/Sistemi_Complessi/2020/10/07/Axelrod_Model-(4).html",
            "relUrl": "/2020/10/07/Axelrod_Model-(4).html",
            "date": " • Oct 7, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "GitHub Actions: Providing Data Scientists With New Superpowers",
            "content": "What Superpowers? . Hi, I’m Hamel Husain. I’m a machine learning engineer at GitHub. Recently, GitHub released a new product called GitHub Actions, which has mostly flown under the radar in the machine learning and data science community as just another continuous integration tool. . Recently, I’ve been able to use GitHub Actions to build some very unique tools for Data Scientists, which I want to share with you today. Most importantly, I hope to get you excited about GitHub Actions, and the promise it has for giving you new superpowers as a Data Scientist. Here are two projects I recently built with Actions that show off its potential: . fastpages . fastpages is an automated, open-source blogging platform with enhanced support for Jupyter notebooks. You save your notebooks, markdown, or Word docs into a directory on GitHub, and they automatically become blog posts. Read the announcement below: . We&#39;re launching `fastpages`, a platform which allows you to host a blog for free, with no ads. You can blog with @ProjectJupyter notebooks, @office Word, directly from @github&#39;s markdown editor, etc.Nothing to install, &amp; setup is automated!https://t.co/dNSA0oQUrN . &mdash; Jeremy Howard (@jeremyphoward) February 24, 2020 Machine Learning Ops . Wouldn’t it be cool if you could invoke a chatbot natively on GitHub to test your machine learning models on the infrastructure of your choice (GPUs), log all the results, and give you a rich report back in a pull request so that everyone could see the results? You can with GitHub Actions! . Consider the below annotated screenshot of this Pull Request: . . A more in-depth explanation about the above project can be viewed in this video: . Using GitHub Actions for machine learning workflows is starting to catch on. Julien Chaumond, CTO of Hugging Face, says: . GitHub Actions are great because they let us do CI on GPUs (as most of our users use the library on GPUs not on CPUs), on our own infra! 1 . Additionally, you can host a GitHub Action for other people so others can use parts of your workflow without having to re-create your steps. I provide examples of this below. . A Gentle Introduction To GitHub Actions . What Are GitHub Actions? . GitHub Actions allow you to run arbitrary code in response to events. Events are activities that happen on GitHub such as: . Opening a pull request | Making an issue comment | Labeling an issue | Creating a new branch | … and many more | . When an event is created, the GitHub Actions context is hydrated with a payload containing metadata for that event. Below is an example of a payload that is received when an issue is created: . { &quot;action&quot;: &quot;created&quot;, &quot;issue&quot;: { &quot;id&quot;: 444500041, &quot;number&quot;: 1, &quot;title&quot;: &quot;Spelling error in the README file&quot;, &quot;user&quot;: { &quot;login&quot;: &quot;Codertocat&quot;, &quot;type&quot;: &quot;User&quot;, }, &quot;labels&quot;: [ { &quot;id&quot;: 1362934389, &quot;node_id&quot;: &quot;MDU6TGFiZWwxMzYyOTM0Mzg5&quot;, &quot;name&quot;: &quot;bug&quot;, } ], &quot;body&quot;: &quot;It looks like you accidently spelled &#39;commit&#39; with two &#39;t&#39;s.&quot; } . This functionality allows you to respond to various events on GitHub in an automated way. In addition to this payload, GitHub Actions also provide a plethora of variables and environment variables that afford easy to access metadata such as the username and the owner of the repo. Additionally, other people can package useful functionality into an Action that other people can inherit. For example, consider the below Action that helps you publish python packages to PyPi: . The Usage section describes how this Action can be used: . - name: Publish a Python distribution to PyPI uses: pypa/gh-action-pypi-publish@master with: user: __token__ password: ${{ secrets.pypi_password }} . This Action expects two inputs: user and a password. You will notice that the password is referencing a variable called secrets, which is a variable that contains an encrypted secret that you can upload to your GitHub repository. There are thousands of Actions (that are free) for a wide variety of tasks that can be discovered on the GitHub Marketplace. The ability to inherit ready-made Actions in your workflow allows you to accomplish complex tasks without implementing all of the logic yourself. Some useful Actions for those getting started are: . actions/checkout: Allows you to quickly clone the contents of your repository into your environment, which you often want to do. This does a number of other things such as automatically mount your repository’s files into downstream Docker containers. | mxschmitt/action-tmate: Proivdes a way to debug Actions interactively. This uses port forwarding to give you a terminal in the browser that is connected to your Actions runner. Be careful not to expose sensitive information if you use this. | actions/github-script: Gives you a pre-authenticated ocotokit.js client that allows you to interact with the GitHub API to accomplish almost any task on GitHub automatically. Only these endpoints are supported (for example, the secrets endpoint is not in that list). | . In addition to the aforementioned Actions, it is helpful to go peruse the official GitHub Actions docs before diving in. . Example: A fastpages Action Workflow . The best to way familiarize yourself with Actions is by studying examples. Let’s take a look at the Action workflow that automates the build of fastpages (the platform used to write this blog post). . Part 1: Define Workflow Triggers . blog, defined in ci.yaml. Like all Actions workflows, this is YAML file is located in the .github/workflows directory of the GitHub repo. . The top of this YAML file looks like this: . name: CI on: push: branches: - master pull_request: . This means that this workflow is triggered on either a push or pull request event. Furthermore, push events are filtered such that only pushes to the master branch will trigger the workflow, whereas all pull requests will trigger this workflow. It is important to note that pull requests opened from forks will have read-only access to the base repository and cannot access any secrets for security reasons. The reason for defining the workflow in this way is we wanted to trigger the same workflow to test pull requests as well as build and deploy the website when a PR is merged into master. This will be clarified as we step through the rest of the YAML file. . Part 2: Define Jobs . Next, we define jobs (there is only one in this workflow). Per the docs: . A workflow run is made up of one or more jobs. Jobs run in parallel by default. . jobs: build-site: if: ( github.event.commits[0].message != &#39;Initial commit&#39; ) || github.run_number &gt; 1 runs-on: ubuntu-latest steps: . The keyword build-site is the name of your job and you can name it whatever you want. In this case, we have a conditional if statement that dictates if this job should be run or not. We are trying to ensure that this workflow does not run when the first commit to a repo is made with the message ‘Initial commit’. The first variable in the if statement, github.event, contains a json payload of the event that triggered this workflow. When developing workflows, it is helpful to print this variable in order to inspect its structure, which you can accomplish with the following YAML: . - name: see payload run: | echo &quot;PAYLOAD: n${PAYLOAD} n&quot; env: PAYLOAD: ${{ toJSON(github.event) }} . Note: the above step is only for debugging and is not currently in the workflow. . toJson is a handy function that returns a pretty-printed JSON representation of the variable. The output is printed directly in the logs contained in the Actions tab of your repo. In this example, printing the payload for a push event will look like this (truncated for brevity): . { &quot;ref&quot;: &quot;refs/tags/simple-tag&quot;, &quot;before&quot;: &quot;6113728f27ae8c7b1a77c8d03f9ed6e0adf246&quot;, &quot;created&quot;: false, &quot;deleted&quot;: true, &quot;forced&quot;: false, &quot;base_ref&quot;: null, &quot;commits&quot;: [ { &quot;message&quot;: &quot;updated README.md&quot;, &quot;author&quot;: &quot;hamelsmu&quot; }, ], &quot;head_commit&quot;: null, } . Therefore, the variable github.event.commits[0].message will retrieve the first commit message in the array of commits. Since we are looking for situations where there is only one commit, this logic suffices. The second variable in the if statement, github.run_number is a special variable in Actions which: . [is a] unique number for each run of a particular workflow in a repository. This number begins at 1 for the workflow’s first run, and increments with each new run. This number does not change if you re-run the workflow run. . Therefore, the if statement introduced above: . if: ( github.event.commits[0].message != &#39;Initial commit&#39; ) || github.run_number &gt; 1 . Allows the workflow to run when the commit message is “Initial commit” as long as it is not the first commit. ( || is a logical or operator). . Finally, the line runs-on: ubuntu-latest specifies the host operating system that your workflows will run in. . Part 3: Define Steps . Per the docs: . A job contains a sequence of tasks called steps. Steps can run commands, run setup tasks, or run an Action in your repository, a public repository, or an Action published in a Docker registry. Not all steps run Actions, but all Actions run as a step. Each step runs in its own process in the runner environment and has access to the workspace and filesystem. Because steps run in their own process, changes to environment variables are not preserved between steps. GitHub provides built-in steps to set up and complete a job. . Below are the first two steps in our workflow: . - name: Copy Repository Contents uses: actions/checkout@master with: persist-credentials: false - name: convert notebooks and word docs to posts uses: ./_action_files . The first step creates a copy of your repository in the Actions file system, with the help of the utility action/checkout. This utility only fetches the last commit by default and saves files into a directory (whose path is stored in the environment variable GITHUB_WORKSPACE that is accessible by subsequent steps in your job. The second step runs the fastai/fastpages Action, which converts notebooks and word documents to blog posts automatically. In this case, the syntax: . uses: ./_action_files . is a special case where the pre-made GitHub Action we want to run happens to be defined in the same repo that runs this workflow. This syntax allows us to test changes to this pre-made Action when evaluating PRs by referencing the directory in the current repository that defines that pre-made Action. Note: Building pre-made Actions is beyond the scope of this tutorial. . The next three steps in our workflow are defined below: . - name: setup directories for Jekyll build run: | rm -rf _site sudo chmod -R 777 . - name: Jekyll build uses: docker://fastai/fastpages-jekyll with: args: bash -c &quot;gem install bundler &amp;&amp; jekyll build -V&quot; env: JEKYLL_ENV: &#39;production&#39; - name: copy CNAME file into _site if CNAME exists run: | sudo chmod -R 777 _site/ cp CNAME _site/ 2&gt;/dev/null || : . The step named setup directories for Jekyll build executes shell commands that remove the _site folder in order to get rid of stale files related to the page we want to build, as well as grant permissions to all the files in our repo to subsequent steps. . The step named Jekyll build executes a docker container hosted by the Jekyll community on Dockerhub called jekyll/jekyll. For those not familiar with Docker, see this tutorial. The name of this container is called fastai/fastpages-jekyll because I’m adding some additional dependencies to jekyll/jekyll and hosting those on my DockerHub account for faster build times2. The args parameter allows you to execute arbitrary commands with the Docker container by overriding the CMD instruction in the Dockerfile. We use this Docker container hosted on Dockerhub so we don’t have to deal with installing and configuring all of the complicated dependencies for Jekyll. The files from our repo are already available in the Actions runtime due to the first step in this workflow, and are mounted into this Docker container automatically for us. In this case, we are running the command jekyll build, which builds our website and places relevant assets them into the _site folder. For more information about Jekyll, read the official docs. Finally, the env parameter allows me to pass an environment variable into the Docker container. . The final command above copies a CNAME file into the _site folder, which we need for the custom domain https://fastpages.fast.ai. Setting up custom domains are outside the scope of this article. . The final step in our workflow is defined below: . - name: Deploy if: github.event_name == &#39;push&#39; uses: peaceiris/actions-gh-pages@v3 with: deploy_key: ${{ secrets.SSH_DEPLOY_KEY }} publish_dir: ./_site . The statement . if: github.event_name == &#39;push&#39; . uses the variable github.event_name to ensure this step only runs when a push event ( in this case only pushes to the master branch trigger this workflow) occur. . This step deploys the fastpages website by copying the contents of the _site folder to the root of the gh-pages branch, which GitHub Pages uses for hosting. This step uses the peaceiris/actions-gh-pages Action, pinned at version 3. Their README describes various options and inputs for this Action. . Conclusion . We hope that this has shed some light on how we use GitHub Actions to automate fastpages. While we only covered one workflow above, we hope this provides enough intuition to understand the other workflows in fastpages. We have only scratched the surface of GitHub Actions in this blog post, but we provide other materials below for those who want to dive in deeper. We have not covered how to host an Action for other people, but you can start with these docs to learn more. . Still confused about how GitHub Actions could be used for Data Science? Here are some ideas of things you can build: . Jupyter Widgets that trigger GitHub Actions to perform various tasks on GitHub via the repository dispatch event | Integration with Pachyderm for data versioning. | Integration with your favorite cloud machine learning services, such Sagemaker, Azure ML or GCP’s AI Platform. | . Related Materials . GitHub Actions official documentation | Hello world Docker Action: A template to demonstrate how to build a Docker Action for other people to use. | Awesome Actions: A curated list of interesting GitHub Actions by topic. | A tutorial on Docker for Data Scientists. | . Getting In Touch . Please feel free to get in touch with us on Twitter: . Hamel Husain @HamelHusain | Jeremy Howard @jeremyphoward | . . Footnotes . You can see some of Hugging Face’s Actions workflows for machine learning on GitHub &#8617; . | These additional dependencies are defined here, which uses the “jekyll build” command to add ruby dedpendencies from the Gemfile located at the root of the repo. Additionally, this docker image is built by another Action workflow defined here. &#8617; . |",
            "url": "https://edoarder.github.io/Sistemi_Complessi/actions/markdown/2020/03/06/fastpages-actions.html",
            "relUrl": "/actions/markdown/2020/03/06/fastpages-actions.html",
            "date": " • Mar 6, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Io sono Edoardo Maggioni, studente del secondo anno di Fisica Teorica presso l’Università di Pisa. . Sono nato a Siena, dove sono cresciuto e dove ho frequentato il corso di laurea triennale in Fisica e Tecnologie Avanzate, laureandomi con lode. . Al di fuori del mondo della fisica ho coltivato svariati hobby, mi piace appassionarmi per certi periodi ad argomenti particolari di mio interesse che vanno dall’informatica al Judo, dall’Ultimate Frisbee all’arte. Il mio interesse principale è la musica, sia ascoltarla che suonarla: riesco ad apprezzare un gran numero di generi musicali, specialmente contemporanei. Suono tastiera e chitarra, ho studiato armonia e qualcosa di composizione. Conosco le basi della produzione musicale analogica e digitale ed ogni tanto faccio qualche brano. Ho infine seguito e conseguito l’esame di Fisica Musicale per il quale ho sviluppato interamente un sintetizzatore con Matlab. . Nella mia vita ho viaggiato tanto, specialmente in Europa, ma punto a viaggiare ancora di più in futuro. . Considero l’originalità uno dei tratti essenziali della vita in generale. .",
          "url": "https://edoarder.github.io/Sistemi_Complessi/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://edoarder.github.io/Sistemi_Complessi/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}